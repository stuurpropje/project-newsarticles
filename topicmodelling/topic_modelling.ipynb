{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking related articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import joblib\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import interact, Layout, HBox, VBox, Box\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = joblib.load('lda_2016.csv')\n",
    "data_vectorized = joblib.load('data_vectorized_2016.csv')\n",
    "vectorizer = joblib.load('vectorizer2016.csv')\n",
    "df = pd.read_csv('../csv/2016_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238411</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.135734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.024726</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.253911</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.122083</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.151994</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085292</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55044</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.355069</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.187572</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55045</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.023087</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.081981</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55046</th>\n",
       "      <td>0.381246</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.106139</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.392331</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55047</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.405778</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.066562</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.031452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.248498</td>\n",
       "      <td>0.016294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55048</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.553887</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55049 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.238411  0.000106  0.000106  0.000106  0.000106  0.000106  0.107994   \n",
       "1      0.000039  0.000039  0.000039  0.000039  0.000039  0.005645  0.000039   \n",
       "2      0.000053  0.000053  0.000053  0.000053  0.000053  0.000053  0.000053   \n",
       "3      0.000042  0.000042  0.000042  0.000042  0.000042  0.000042  0.000042   \n",
       "4      0.000120  0.122083  0.000120  0.000120  0.000120  0.000120  0.151994   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "55044  0.000038  0.000038  0.000038  0.000038  0.000038  0.000038  0.000038   \n",
       "55045  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "55046  0.381246  0.000102  0.000102  0.106139  0.000102  0.000102  0.392331   \n",
       "55047  0.000055  0.000055  0.000055  0.405778  0.000055  0.000055  0.066562   \n",
       "55048  0.000114  0.000114  0.000114  0.000114  0.000114  0.000114  0.000114   \n",
       "\n",
       "             7         8         9   ...        40        41        42  \\\n",
       "0      0.000106  0.000106  0.000106  ...  0.000106  0.000106  0.000106   \n",
       "1      0.000039  0.000039  0.135734  ...  0.000039  0.000039  0.000039   \n",
       "2      0.000053  0.090053  0.000053  ...  0.000053  0.000053  0.000053   \n",
       "3      0.000042  0.009310  0.006844  ...  0.000042  0.000042  0.000042   \n",
       "4      0.000120  0.000120  0.019859  ...  0.085292  0.000120  0.000120   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "55044  0.355069  0.000038  0.000038  ...  0.000038  0.187572  0.000038   \n",
       "55045  0.023087  0.000058  0.000058  ...  0.000058  0.000058  0.000058   \n",
       "55046  0.000102  0.000102  0.000102  ...  0.000102  0.000102  0.000102   \n",
       "55047  0.000055  0.000055  0.031452  ...  0.008498  0.000055  0.000055   \n",
       "55048  0.553887  0.000114  0.000114  ...  0.000114  0.000114  0.000114   \n",
       "\n",
       "             43        44        45        46        47        48        49  \n",
       "0      0.000106  0.000106  0.000106  0.000106  0.000106  0.000106  0.000106  \n",
       "1      0.024726  0.000039  0.000039  0.000039  0.000039  0.000039  0.000039  \n",
       "2      0.008197  0.000053  0.000053  0.000053  0.000053  0.077419  0.000053  \n",
       "3      0.000042  0.253911  0.000042  0.000042  0.000042  0.000042  0.000042  \n",
       "4      0.000120  0.000120  0.000120  0.000120  0.000120  0.084412  0.000120  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "55044  0.000038  0.000038  0.000038  0.000038  0.000038  0.000038  0.000038  \n",
       "55045  0.000058  0.081981  0.000058  0.000058  0.000058  0.000058  0.000058  \n",
       "55046  0.007279  0.000102  0.000102  0.000102  0.000102  0.000102  0.000102  \n",
       "55047  0.000055  0.000055  0.000055  0.000055  0.000055  0.248498  0.016294  \n",
       "55048  0.000114  0.000114  0.000114  0.000114  0.000114  0.000114  0.000114  \n",
       "\n",
       "[55049 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist = pd.DataFrame(lda.transform(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, vectorizer, n_top_words):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0: use like make new not technology one also design camera get work app look system vr you device well car google even video build way\n",
      "\n",
      "Topic #1: say police court case officer charge judge report law arrest lawyer crime justice attorney accord lawsuit tell prosecutor claim file investigation statement prison trial department\n",
      "\n",
      "Topic #2: song music album band record space release year new track time not first one video last show make singer take fight like go fan tour\n",
      "\n",
      "Topic #3: health say drug study patient use medical people dr care research doctor find one year also not disease researcher cancer treatment new may percent would\n",
      "\n",
      "Topic #4: zika option next section indicate icon previous menu sometimes virus chevron navigation expandable case outbreak mosquito say health spread pregnant disease woman infection microcephaly infect\n",
      "\n",
      "Topic #5: de brazil la brazilian rio mexico le ford paulo et des janeiro rousseff du sao mexican un sa il paris city est les france en\n",
      "\n",
      "Topic #6: company say business million billion deal year market firm sell industry sale investment executive new group plan would buy include investor also offer report last\n",
      "\n",
      "Topic #7: say house would senate bill president obama committee congress republican vote court republicans democrats leader year rule senator lawmaker member not sen trump supreme could\n",
      "\n",
      "Topic #8: say russia iran russian saudi united states president foreign nuclear country putin we sanction deal would official mr world arabia moscow obama iranian international minister\n",
      "\n",
      "Topic #9: school student make restaurant college say one food year university like cook wine get teacher coffee work class education day not chef serve use drink\n",
      "\n",
      "Topic #10: people black gun white woman community right law say gay many america violence political american gender president one man issue use make group also country\n",
      "\n",
      "Topic #11: not do go like get think people say know want make thing one re really time would you ve that see way feel good come\n",
      "\n",
      "Topic #12: game season first run two point hit start say last three second score lead get play win go four one five team inning home make\n",
      "\n",
      "Topic #13: climate car say year vehicle change world emission global could planet scientist new fuel carbon earth air we temperature storm sea weather ocean ice one\n",
      "\n",
      "Topic #14: hill view washington dc discussion street inc corp 2019 communications 900 content subsidiary capitol suite publishing news site tel thread fax nw 1625 2026288500 2026288503\n",
      "\n",
      "Topic #15: china chinese say beijing trade we country taiwan year south government foreign international shanghai official us states united asia also sea fcc yuan asian report\n",
      "\n",
      "Topic #16: say state government syria islamic force group refugee syrian attack isis turkey war military iraq country people year last border would militant security party official\n",
      "\n",
      "Topic #17: say mr email new official department report fbi former investigation state director release news letter york secretary president information statement intelligence write friday tell national\n",
      "\n",
      "Topic #18: say people woman kill country group right year police attack mr one man government war israel protest force military many human family two muslim violence\n",
      "\n",
      "Topic #19: clinton campaign state vote voter election sander say democratic candidate percent poll party hillary trump win presidential new republican primary support president race bernie lead\n",
      "\n",
      "Topic #20: apple company app iphone new service google customer phone amazon product store say device also year consumer mobile samsung microsoft use make user smartphone not\n",
      "\n",
      "Topic #21: million company source coverage text share reuters reuter per eikon say 2016 newsroom inc revenue year earning euro ltd net report co billion versus bengaluru\n",
      "\n",
      "Topic #22: security information use datum government say law attack privacy system access hack abortion would company case email fbi one not could internet report agency hacker\n",
      "\n",
      "Topic #23: trump say donald mr campaign republican not trumps would president clinton cruz presidential candidate do make election go debate he new one call party hillary\n",
      "\n",
      "Topic #24: team game player say sport play year win coach one league world first football athlete time make two take match fan olympic last go would\n",
      "\n",
      "Topic #25: cramer say stock fund company airport money airline hedge investor take gawker travel cohen one not passenger hogan thiel make get time year jim capital\n",
      "\n",
      "Topic #26: book show season episode story series character one write not new read novel first get also see writer make like fan go end know tv\n",
      "\n",
      "Topic #27: hill not do say trump senate dc news capitol view run site thread suite 900 communications 2019 street fax publishing inc corp tel washington discussion\n",
      "\n",
      "Topic #28: art work artist music museum one new make world show create piece exhibition like image project painting paint also dance history gallery culture form way\n",
      "\n",
      "Topic #29: percent price market oil rate say high we stock low rise fall year week dollar since last crude fed point index gain month new report\n",
      "\n",
      "Topic #30: colbert good stephen democratic candidate el roast meyer jackson dad giphy high bon emoji seth via school debate offer story impression destroy scandal animal different\n",
      "\n",
      "Topic #31: mr award year prince show star actor say first film good new also long oscar royal include father actress night role son performance die hamilton\n",
      "\n",
      "Topic #32: look wear fashion woman new dress show photo star instagram hair say love also not girl one share take make get she post kardashian year\n",
      "\n",
      "Topic #33: say pay money company tax financial new business make employee work million would worker job fund bank mr year uber not also one account take\n",
      "\n",
      "Topic #34: say european britain eu union minister british would europe uk london leave vote france brexit french country prime government referendum may tell germany attack brussels\n",
      "\n",
      "Topic #35: film game movie like one play make not star new character year also time well get first way world good see show war take story\n",
      "\n",
      "Topic #36: state would government year law say country people program federal public new make policy many states plan tax one million system american united immigration canada\n",
      "\n",
      "Topic #37: food eat you re today moon time get not make sign new diet also sugar day good milk ll do like fat way people come\n",
      "\n",
      "Topic #38: one say not like get time go man back come day take tell know would do make friend life family see could night love he\n",
      "\n",
      "Topic #39: north korea south report korean dog security nuclear cat information animal kim test koreas fitch japan particular seoul issue pet verification missile make use launch\n",
      "\n",
      "Topic #40: say flight air plane report military aircraft ship would force fly defense we passenger pilot airline official rocket union russian jet united test us international\n",
      "\n",
      "Topic #41: water say energy state gas oil power plant environmental land use flint coal city project year natural lead area clean farmer farm industry supply government\n",
      "\n",
      "Topic #42: city new mr york street park say building include west home year house hotel ms open theater manhattan build brooklyn work space center live project\n",
      "\n",
      "Topic #43: facebook medium video twitter news social user post content ad people new online story internet live like platform company site tweet network say app also\n",
      "\n",
      "Topic #44: percent bank say year market billion report growth rate rise fall quarter share economy expect investor analyst euro bond central last low stock month financial\n",
      "\n",
      "Topic #45: pm 10 street saturday hong kong sunday friday australia july march australian new art free 11 tuesday center monday thursday wednesday avenue 30 april may\n",
      "\n",
      "Topic #46: rating fitch credit debt loan bank rate available financial risk capital senior issuer entity criterion support follow provide service 2016 expect market 2015 term also\n",
      "\n",
      "Topic #47: 2016 photo post november august pdt july january october september 14 2015 march 13 december 29 pst comment mashable thailand 18 anthem 22 27 24\n",
      "\n",
      "Topic #48: say people ms one tell family go day two fire see child take home time not man find leave die mother hour year life hospital\n",
      "\n",
      "Topic #49: race gold cnbc olympic world ticket year golf say fox second first medal event horse win last finish time rio day swimmer one two tour\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, vectorizer, n_top_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_docs(doc_dist, k=5, get_dist=False):\n",
    "    '''\n",
    "    doc_dist: topic distribution (sums to 1) of one article\n",
    "    \n",
    "    Returns the index of the k nearest articles (as by Jensen–Shannon divergence in topic space). \n",
    "    '''\n",
    "    temp = doc_topic_dist\n",
    "         \n",
    "    distances = temp.apply(lambda x: jensenshannon(x, doc_dist), axis=1)\n",
    "    k_nearest = distances[distances != 0].nsmallest(n=k).index\n",
    "    \n",
    "    if get_dist:\n",
    "        k_distances = distances[distances != 0].nsmallest(n=k)\n",
    "        return k_nearest, k_distances\n",
    "    else:\n",
    "        return k_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_article_dna(title, width=20):\n",
    "    t = df[df['title'] == title].title.values[0]\n",
    "    doc_topic_dist[df['title'] == title].T.plot(kind='bar', legend=None, title=t, figsize=(width, 4))\n",
    "    plt.xlabel('Topic')\n",
    "\n",
    "def compare_dnas(title, recommendation_title, width=20):\n",
    "    t = df[df['title'] == recommendation_title].title.values[0]\n",
    "    temp = doc_topic_dist[df['title'] == title]\n",
    "    ymax = temp.max(axis=1).values[0]*1.25\n",
    "    temp = pd.concat([temp, doc_topic_dist[df['title'] == recommendation_title]])\n",
    "    temp.T.plot(kind='bar', title=t, figsize=(width, 4), ylim= [0, ymax])\n",
    "    plt.xlabel('Topic')\n",
    "    plt.legend(['Selection', 'Recommendation'])\n",
    "\n",
    "def dna_tabs(titles):\n",
    "    k = len(titles)\n",
    "    outs = [widgets.Output() for i in range(k)]\n",
    "\n",
    "    tab = widgets.Tab(children = outs)\n",
    "    tab_titles = ['Paper ' + str(i+1) for i in range(k)]\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        tab.set_title(i, t)\n",
    "    display(tab)\n",
    "\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        with outs[i]:\n",
    "            ax = plot_article_dna(titles[i])\n",
    "            plt.show(ax)\n",
    "\n",
    "def compare_tabs(title, recommendation_ids):\n",
    "    k = len(recommendation_ids)\n",
    "    outs = [widgets.Output() for i in range(k)]\n",
    "\n",
    "    tab = widgets.Tab(children = outs)\n",
    "    tab_titles = ['Paper ' + str(i+1) for i in range(k)]\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        tab.set_title(i, t)\n",
    "    display(tab)\n",
    "\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        with outs[i]:\n",
    "            ax = compare_dnas(title, recommendation_ids[i])\n",
    "            plt.show(ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(title, k=5, plot_dna=False):\n",
    "    '''\n",
    "    Returns the title of the k papers that are closest (topic-wise) to the paper given through title.\n",
    "    '''\n",
    "    display(df[df.title == title])\n",
    "\n",
    "    recommended, dist = get_k_nearest_docs(doc_topic_dist[df['title'] == title].iloc[0], k, get_dist=True)\n",
    "    recommended = df.iloc[recommended].copy()\n",
    "    recommended['similarity'] = 1 - dist \n",
    "    \n",
    "    h = '<br/>'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n + '</a>' +' (Similarity: ' + \"{:.2f}\".format(s) + ')' for l, n, s in recommended[['url','title', 'similarity']].values])\n",
    "    display(HTML(h))\n",
    "    \n",
    "    if plot_dna:\n",
    "        compare_tabs(title, recommended['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health Watch: Back Pain Overview</td>\n",
       "      <td>graphiq i d 1zj8ypuuhbz graphiq i d 86h0dyo1d8...</td>\n",
       "      <td>http://www.reuters.com/article/us-healthwatch-...</td>\n",
       "      <td>Journalists</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        date  month  day author                             title  \\\n",
       "7106  2016  2016-08-03    8.0    3    NaN  Health Watch: Back Pain Overview   \n",
       "\n",
       "                                                article  \\\n",
       "7106  graphiq i d 1zj8ypuuhbz graphiq i d 86h0dyo1d8...   \n",
       "\n",
       "                                                    url      section  \\\n",
       "7106  http://www.reuters.com/article/us-healthwatch-...  Journalists   \n",
       "\n",
       "     publication  \n",
       "7106     Reuters  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.vice.com/en_us/article/bmwe75/meet-the-biggest-pipe-in-the-world\" target=\"_blank\">Meet the Biggest Pipe in the World</a> (Similarity: 0.97)<br/><a href=\"https://www.theverge.com/video/2016/1/20/10799220/apple-music-memos-hands-on-demo\" target=\"_blank\">Apple Music Memos makes mobile recording easy</a> (Similarity: 0.87)<br/><a href=\"https://www.theverge.com/video/2016/1/5/10711622/windows-10-mobile-alcatel-tablet-ces-2016\" target=\"_blank\">First look at Windows 10 Mobile on an 8-inch tablet</a> (Similarity: 0.78)<br/><a href=\"https://www.vox.com/2016/12/20/14025718/apple-extends-usb-dongle-discounts\" target=\"_blank\">Apple has extended its USB dongle discounts through March</a> (Similarity: 0.77)<br/><a href=\"https://www.buzzfeednews.com/article/josephbernstein/apple-pay-is-coming-to-mac-os\" target=\"_blank\">Apple Pay Is Coming To Mac OS</a> (Similarity: 0.76)<br/><a href=\"https://www.theverge.com/2016/10/13/13267760/samsung-telling-s7-owners-phone-safe-note-7-recall\" target=\"_blank\">Samsung is reportedly telling S7 owners their phones are safe because the Galaxy is confusing</a> (Similarity: 0.75)<br/><a href=\"https://www.theverge.com/2016/8/30/12720050/apple-icloud-storage-2tb-option-iphone-7-launch\" target=\"_blank\">Apple adds 2TB iCloud storage option before iPhone 7 launch</a> (Similarity: 0.75)<br/><a href=\"https://techcrunch.com/2016/05/12/walmart-begins-testing-2-day-shipping-service-to-take-on-amazon-prime/\" target=\"_blank\">Walmart begins testing 2-day shipping service to take on Amazon Prime – TechCrunch</a> (Similarity: 0.75)<br/><a href=\"https://www.cnbc.com/2016/10/19/apple-plans-to-launch-new-macs-at-an-october-27-event.html\" target=\"_blank\">Apple plans to launch new Macs at an October 27 event</a> (Similarity: 0.75)<br/><a href=\"https://www.theverge.com/2016/2/2/10893620/microsoft-windows-10-upgrade-recommended-update\" target=\"_blank\">Microsoft is now aggressively pushing Windows 10 upgrades</a> (Similarity: 0.75)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb639c1ac89d475483158797524cc8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendation(\"Health Watch: Back Pain Overview\", k=10, plot_dna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_articles(tasks, k=5):\n",
    "    tasks = [tasks] if type(tasks) is str else tasks \n",
    "    \n",
    "    tasks_vectorized = vectorizer.transform(tasks)\n",
    "    tasks_topic_dist = pd.DataFrame(lda.transform(tasks_vectorized))\n",
    "\n",
    "    for index, bullet in enumerate(tasks):\n",
    "        print(bullet)\n",
    "        recommended, dist = get_k_nearest_docs(tasks_topic_dist.iloc[index], k, get_dist=True)\n",
    "        recommended = df.iloc[recommended].copy()\n",
    "        recommended['similarity'] = 1 - dist \n",
    "\n",
    "        h = '<br/>'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n + '</a>' +' (Similarity: ' + \"{:.2f}\".format(s) + ')' for l, n, s in recommended[['url','title', 'similarity']].values])\n",
    "        display(HTML(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_articles_for_text():    \n",
    "    textW = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Type something',\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        layout=Layout(width='90%', height='200px')\n",
    "    )\n",
    "\n",
    "    kWidget = widgets.IntSlider(value=10, description='Number of articles', max=50, min=1, layout=Layout(width='50%'))\n",
    "\n",
    "    button = widgets.Button(description=\"Search\")\n",
    "\n",
    "    display(VBox([HBox([kWidget], layout=Layout(width='90%', justify_content='space-around')),\n",
    "        textW, button], layout=Layout(align_items='center')))\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        clear_output()\n",
    "        display(VBox([HBox([kWidget], layout=Layout(width='90%', justify_content='space-around')),\n",
    "            textW, button], layout=Layout(align_items='center')))        \n",
    "        relevant_articles(textW.value, kWidget.value)\n",
    "\n",
    "    button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c06e497b3348ee8b00a7d95da095cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=10, description='Number of articles', layout=Layout(width='50%')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.buzzfeednews.com/article/eimiyamamitsu/surprise-successful-dogs-reaction-to-magic-tr\" target=\"_blank\">This Is What Happens When You Do Magic For A Dog</a> (Similarity: 0.70)<br/><a href=\"https://people.com/celebrity/skydiver-kevin-burkart-jumps-for-parkinsons-research/\" target=\"_blank\">Skydiver Kevin Burkart Jumps for Parkinson's Research</a> (Similarity: 0.57)<br/><a href=\"https://people.com/pets/navy-finds-german-shepard-that-was-lost-at-sea-for-five-weeks/\" target=\"_blank\">Navy Finds German Shepard That Was Lost at Sea for Five Weeks</a> (Similarity: 0.57)<br/><a href=\"https://www.buzzfeednews.com/article/tanyachen/but-hashtag-notallclowns-tho\" target=\"_blank\">People Are So Afraid Of Clowns This Year That It’s Become A Meme</a> (Similarity: 0.57)<br/><a href=\"https://www.wired.com/2016/11/saving-america-with-a-text\" target=\"_blank\">Saving America With a Text</a> (Similarity: 0.57)<br/><a href=\"https://mashable.com/2016/10/13/trumpkin-donald-trump-pumpkin/\" target=\"_blank\">The Trumpkin is back to make Halloween terrifying again</a> (Similarity: 0.56)<br/><a href=\"https://mashable.com/2016/09/15/mid-autumn-festival-asia/\" target=\"_blank\">Mid-Autumn Festival in Asia kicks off with dragons lanterns and mooncakes</a> (Similarity: 0.56)<br/><a href=\"https://mashable.com/2016/10/17/family-halloween-costume-ideas/\" target=\"_blank\">30 Halloween costumes that bring the family together</a> (Similarity: 0.56)<br/><a href=\"https://mashable.com/2016/09/06/burning-man-2016-instagram-pics/\" target=\"_blank\">50 dope Instagram pictures from Burning Man 2016</a> (Similarity: 0.56)<br/><a href=\"https://mashable.com/2016/03/04/chihuahua-cat-instagram/\" target=\"_blank\">A fluffy cat is the leader of this adorable chihuahua family</a> (Similarity: 0.55)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevant_articles_for_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
